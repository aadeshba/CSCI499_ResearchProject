{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from io import open\n",
    "\n",
    "file_path = \"2020_acl_diplomacy/data/train.jsonl\"\n",
    "train_data = {}\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        # Parse the line as JSON\n",
    "        train_data[i] = json.loads(line)\n",
    "        i+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Russia. Have you worked out what you‚Äôre doing with turkey and Austria yet? I‚Äôm thinking of going anti Germany but want to see how we align in the north first. False NOANNOTATION\n",
      "I sent Turkey a message but still waiting on a reply. I wanted to go anti-Germany too if you want to split the population centers? But if I don‚Äôt hear back from Turkey I may have to fortify my South flank and enter the Balkan‚Äôs even though I don‚Äôt want to. True NOANNOTATION\n",
      "I moving to pressureGermany but I could use assistance on your end. Willing to share any gains that could result. True True\n",
      "Yikes. You have some Turkish trouble. I‚Äôll plan on moving into helgoland bight True NOANNOTATION\n",
      "Yea, that‚Äôs always annoying playing as Russia. Trying to get AH to help out but I have to move one of my troops back West away from pressuring Germany. Oh well. True True\n",
      "That‚Äôs a shame. Let‚Äôs reassess after you handle your problems in the east. True NOANNOTATION\n",
      "Hey man. Let me know if you wanna support my fleet moving to Sweden. Would pressure Germany and keep me a,Ive with a new supply center in my fight in the sky th with Turkey. I‚Äôm gonna need all the help I can get there but have AH help to keep me alive down there. True True\n",
      "Yes, Turkey has been a real thorn in your side. I‚Äôd like to see some pressure on Germany to ease off my unit in Belgium. If I support you into Sweden, will you support me into Denmark? True True\n",
      "Definitely. True NOANNOTATION\n"
     ]
    }
   ],
   "source": [
    "# print(len(diplomacy_data))\n",
    "# for key, value in diplomacy_data[27].items():\n",
    "#     print(\"Key: \", key)\n",
    "messages_26= train_data[36][\"messages\"]\n",
    "sender_26= train_data[36][\"sender_labels\"]\n",
    "receiever_26= train_data[36][\"receiver_labels\"]\n",
    "\n",
    "# print(len(messages_26), len(sender_26), len(receiever_26))\n",
    "\n",
    "i=0\n",
    "for message in messages_26:\n",
    "    print(message, sender_26[i], receiever_26[i])\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/homebrew/lib/python3.9/site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.9/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/aadeshbajaj/Library/Python/3.9/lib/python/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.9/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/aadeshbajaj/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13132 13132\n",
      "context: Germany!\n",
      "\n",
      "Just the person I want to speak with. I have a somewhat crazy idea that I‚Äôve always wanted to try with I/G, but I‚Äôve never actually convinced the other guy to try it. And, what‚Äôs worse, it might make you suspicious of me. \n",
      "\n",
      "So...do I suggest it?\n",
      "\n",
      "I‚Äôm thinking that this is a low stakes game, not a tournament or anything, and an interesting and unusual move set might make it more fun? That‚Äôs my hope anyway.\n",
      "\n",
      "What is your appetite like for unusual and crazy? You've whet my appetite, Italy. What's the suggestion? üëç classify: It seems like there are a lot of ways that could go wrong...I don't see why France would see you approaching/taking Munich--while I do nothing about it--and not immediately feel skittish\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "\n",
    "inputs, targets = [], []\n",
    "\n",
    "for key, instance in train_data.items():\n",
    "    if isinstance(instance, dict) and 'messages' in instance:\n",
    "        messages = instance['messages']\n",
    "        sender_labels = instance['sender_labels']\n",
    "\n",
    "    for idx, (message, label) in enumerate(zip(messages, sender_labels)):\n",
    "        start_index = max(0, idx-10)\n",
    "        end_index = min(len(messages)-1, idx)\n",
    "        context = \" \".join(messages[start_index:end_index])\n",
    "        inputs.append(f\"context: {context} classify: {message}\")\n",
    "        targets.append(\"true\" if label else \"false\")\n",
    "\n",
    "\n",
    "print(len(inputs), len(targets)) \n",
    "print(inputs[3])\n",
    "print(targets[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentencepiece in /opt/homebrew/lib/python3.9/site-packages (0.1.99)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "train_encodings = tokenizer(inputs, truncation=True, padding='max_length', max_length=512)\n",
    "train_labels = tokenizer(targets, truncation=True, padding='max_length', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /opt/homebrew/lib/python3.9/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.9/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/aadeshbajaj/Library/Python/3.9/lib/python/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.9/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DiplomacyDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = DiplomacyDataset(train_encodings, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"2020_acl_diplomacy/data/validation.jsonl\"\n",
    "validation_data = {}\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        # Parse the line as JSON\n",
    "        validation_data[i] = json.loads(line)\n",
    "        i+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts = []\n",
    "targetval_texts = []\n",
    "\n",
    "for key, instance in validation_data.items():\n",
    "    messages_str = ' '.join(instance['messages'])\n",
    "    labels_str = ' '.join(map(str, instance['sender_labels']))\n",
    "    val_texts.append(messages_str)\n",
    "    targetval_texts.append(labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_encodings = tokenizer(val_texts, truncation=True, padding='max_length', max_length=512)\n",
    "val_labels = tokenizer(targetval_texts, truncation=True, padding='max_length', max_length=512)\n",
    "val_dataset = DiplomacyDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:21<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 21.8171, 'train_samples_per_second': 0.275, 'train_steps_per_second': 0.138, 'train_loss': 16.02013905843099, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 45.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 16.306488037109375, 'eval_runtime': 0.4979, 'eval_samples_per_second': 4.017, 'eval_steps_per_second': 2.009, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 1444.82it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (2, 2, 512) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/aadeshbajaj/CSCI499_ResearchProject/clean_data.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aadeshbajaj/CSCI499_ResearchProject/clean_data.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m prediction_outputs \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mpredict(val_dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aadeshbajaj/CSCI499_ResearchProject/clean_data.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m predictions, true_labels \u001b[39m=\u001b[39m prediction_outputs\u001b[39m.\u001b[39mpredictions, prediction_outputs\u001b[39m.\u001b[39mlabel_ids\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aadeshbajaj/CSCI499_ResearchProject/clean_data.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m predicted_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margmax(prediction_outputs\u001b[39m.\u001b[39;49mpredictions, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aadeshbajaj/CSCI499_ResearchProject/clean_data.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(predicted_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aadeshbajaj/CSCI499_ResearchProject/clean_data.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# f1 = f1_score(true_labels, predictions)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aadeshbajaj/CSCI499_ResearchProject/clean_data.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# print(f\"F1 Score: {f1}\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[39mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m-> 1229\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/numpy/core/fromnumeric.py:56\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, method, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/numpy/core/fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(asarray(obj), method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (2, 2, 512) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# %pip install allennlp\n",
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "# from allennlp.training.metrics import F1Measure\n",
    "# from allennlp.training.metrics.fbeta_measure import FBetaMeasure\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "for i in range(10):\n",
    "    trainer.train()\n",
    "    trainer.save_model(f\"./results/model_{i}\")\n",
    "    results = trainer.evaluate(val_dataset)\n",
    "    print(results)\n",
    "\n",
    "    prediction_outputs = trainer.predict(val_dataset)\n",
    "    predictions, true_labels = prediction_outputs.predictions, prediction_outputs.label_ids\n",
    "    predicted_labels = np.argmax(prediction_outputs.predictions, axis=1)\n",
    "    print(predicted_labels)\n",
    "    # f1 = f1_score(true_labels, predictions)\n",
    "    # print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    acc = accuracy_score(true_labels, predicted_labels)\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "\n",
    "# print accuracy and loss at each step\n",
    "# what is the input and what is expected output for both classification and generation\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
