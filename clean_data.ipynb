{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from io import open\n",
    "\n",
    "file_path = \"2020_acl_diplomacy/data/train.jsonl\"\n",
    "train_data = {}\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        # Parse the line as JSON\n",
    "        train_data[i] = json.loads(line)\n",
    "        i+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"2020_acl_diplomacy/data/test.jsonl\"\n",
    "test_data = {}\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        # Parse the line as JSON\n",
    "        test_data[i] = json.loads(line)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Russia. Have you worked out what you‚Äôre doing with turkey and Austria yet? I‚Äôm thinking of going anti Germany but want to see how we align in the north first. False NOANNOTATION\n",
      "I sent Turkey a message but still waiting on a reply. I wanted to go anti-Germany too if you want to split the population centers? But if I don‚Äôt hear back from Turkey I may have to fortify my South flank and enter the Balkan‚Äôs even though I don‚Äôt want to. True NOANNOTATION\n",
      "I moving to pressureGermany but I could use assistance on your end. Willing to share any gains that could result. True True\n",
      "Yikes. You have some Turkish trouble. I‚Äôll plan on moving into helgoland bight True NOANNOTATION\n",
      "Yea, that‚Äôs always annoying playing as Russia. Trying to get AH to help out but I have to move one of my troops back West away from pressuring Germany. Oh well. True True\n",
      "That‚Äôs a shame. Let‚Äôs reassess after you handle your problems in the east. True NOANNOTATION\n",
      "Hey man. Let me know if you wanna support my fleet moving to Sweden. Would pressure Germany and keep me a,Ive with a new supply center in my fight in the sky th with Turkey. I‚Äôm gonna need all the help I can get there but have AH help to keep me alive down there. True True\n",
      "Yes, Turkey has been a real thorn in your side. I‚Äôd like to see some pressure on Germany to ease off my unit in Belgium. If I support you into Sweden, will you support me into Denmark? True True\n",
      "Definitely. True NOANNOTATION\n"
     ]
    }
   ],
   "source": [
    "# print(len(diplomacy_data))\n",
    "# for key, value in diplomacy_data[27].items():\n",
    "#     print(\"Key: \", key)\n",
    "messages_26= train_data[36][\"messages\"]\n",
    "sender_26= train_data[36][\"sender_labels\"]\n",
    "receiever_26= train_data[36][\"receiver_labels\"]\n",
    "\n",
    "# print(len(messages_26), len(sender_26), len(receiever_26))\n",
    "\n",
    "i=0\n",
    "for message in messages_26:\n",
    "    print(message, sender_26[i], receiever_26[i])\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/homebrew/lib/python3.9/site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.9/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/aadeshbajaj/Library/Python/3.9/lib/python/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/aadeshbajaj/Library/Python/3.9/lib/python/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/aadeshbajaj/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "13132 13132\n",
      "context: Germany!\n",
      "\n",
      "Just the person I want to speak with. I have a somewhat crazy idea that I‚Äôve always wanted to try with I/G, but I‚Äôve never actually convinced the other guy to try it. And, what‚Äôs worse, it might make you suspicious of me. \n",
      "\n",
      "So...do I suggest it?\n",
      "\n",
      "I‚Äôm thinking that this is a low stakes game, not a tournament or anything, and an interesting and unusual move set might make it more fun? That‚Äôs my hope anyway.\n",
      "\n",
      "What is your appetite like for unusual and crazy? You've whet my appetite, Italy. What's the suggestion? üëç classify: It seems like there are a lot of ways that could go wrong...I don't see why France would see you approaching/taking Munich--while I do nothing about it--and not immediately feel skittish\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "# from transformers import T5Tokenizer\n",
    "\n",
    "\n",
    "inputs, targets = [], []\n",
    "\n",
    "for key, instance in train_data.items():\n",
    "    if isinstance(instance, dict) and 'messages' in instance:\n",
    "        messages = instance['messages']\n",
    "        sender_labels = instance['sender_labels']\n",
    "\n",
    "    for idx, (message, label) in enumerate(zip(messages, sender_labels)):\n",
    "        start_index = max(0, idx-10)\n",
    "        end_index = min(len(messages)-1, idx)\n",
    "        context = \" \".join(messages[start_index:end_index])\n",
    "        inputs.append(f\"context: {context} classify: {message}\")\n",
    "        targets.append(\"true\" if label else \"false\")\n",
    "\n",
    "\n",
    "print(len(inputs), len(targets)) \n",
    "print(inputs[3])\n",
    "print(targets[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs, test_targets = [], []\n",
    "\n",
    "for key, instance in test_data.items():\n",
    "    if isinstance(instance, dict) and 'messages' in instance:\n",
    "        messages = instance['messages']\n",
    "        sender_labels = instance['sender_labels']\n",
    "\n",
    "    for idx, (message, label) in enumerate(zip(messages, sender_labels)):\n",
    "        start_index = max(0, idx-10)\n",
    "        end_index = min(len(messages)-1, idx)\n",
    "        context = \" \".join(messages[start_index:end_index])\n",
    "        test_inputs.append(f\"context: {context} classify: {message}\")\n",
    "        test_targets.append(\"true\" if label else \"false\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentencepiece in /opt/homebrew/lib/python3.9/site-packages (0.1.99)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# train_encodings = tokenizer(inputs, truncation=True, padding='max_length', max_length=512)\n",
    "# train_labels = tokenizer(targets, truncation=True, padding='max_length', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /opt/homebrew/lib/python3.9/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.9/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/aadeshbajaj/Library/Python/3.9/lib/python/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.9/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DiplomacyDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "        assert len(self.encodings['input_ids']) == len(self.labels['input_ids']), \"Encodings and labels must have the same number of samples.\"\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# train_dataset = DiplomacyDataset(train_encodings, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: imbalanced-learn in /opt/homebrew/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/homebrew/lib/python3.9/site-packages (from imbalanced-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/homebrew/lib/python3.9/site-packages (from imbalanced-learn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/homebrew/lib/python3.9/site-packages (from imbalanced-learn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.9/site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from imbalanced-learn) (3.2.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"2020_acl_diplomacy/data/validation.jsonl\"\n",
    "validation_data = {}\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        # Parse the line as JSON\n",
    "        validation_data[i] = json.loads(line)\n",
    "        i+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts, targetval_texts = [], []\n",
    "\n",
    "for key, instance in validation_data.items():\n",
    "    if isinstance(instance, dict) and 'messages' in instance:\n",
    "        messages = instance['messages']\n",
    "        sender_labels = instance['sender_labels']\n",
    "\n",
    "    for idx, (message, label) in enumerate(zip(messages, sender_labels)):\n",
    "        start_index = max(0, idx-10)\n",
    "        end_index = min(len(messages)-1, idx)\n",
    "        context = \" \".join(messages[start_index:end_index])\n",
    "        val_texts.append(f\"context: {context} classify: {message}\")\n",
    "        targetval_texts.append(\"true\" if label else \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13132\n",
      "Shape of X: (17557, 768)\n",
      "Shape of Y: (17557,)\n"
     ]
    }
   ],
   "source": [
    "# %pip install allennlp\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "val_encodings = tokenizer(val_texts, return_tensors=\"pt\", padding='max_length', max_length=512, truncation=True)\n",
    "# val_labels = tokenizer(targetval_texts, truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "# Pass inputs to the model\n",
    "# x_outputs = model(**inputs)\n",
    "x_embeddings = []\n",
    "\n",
    "print(len(inputs))\n",
    "for text in inputs:\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding='max_length', max_length=512, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    # print(outputs.pooler_output[0].numpy().shape)\n",
    "    x_embeddings.append(outputs.pooler_output.squeeze().numpy())\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.5, k_neighbors=3, random_state=42)\n",
    "\n",
    "X = np.stack(x_embeddings)\n",
    "Y = np.array(targets)  \n",
    "X_resampled, Y_resampled = smote.fit_resample(X, Y)\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X_resampled)\n",
    "clf = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
    "\n",
    "clf.fit(X_resampled, Y_resampled)\n",
    "\n",
    "\n",
    "print(\"Shape of X:\", X_resampled.shape)\n",
    "print(\"Shape of Y:\", Y_resampled.shape)\n",
    "# clf.fit(X_resampled, Y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2741\n",
      "Accuracy: 0.7526450200656695\n"
     ]
    }
   ],
   "source": [
    "x_test_embeddings = []\n",
    "\n",
    "print(len(test_inputs))\n",
    "for text in test_inputs:\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding='max_length', max_length=512, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    # print(outputs.pooler_output[0].numpy().shape)\n",
    "    x_test_embeddings.append(outputs.pooler_output.squeeze().numpy())\n",
    "\n",
    "\n",
    "X_test = np.stack(x_test_embeddings)\n",
    "Y_test = np.array(test_targets)  \n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.13      0.32      0.19       240\n",
      "        true       0.92      0.79      0.85      2501\n",
      "\n",
      "    accuracy                           0.75      2741\n",
      "   macro avg       0.53      0.56      0.52      2741\n",
      "weighted avg       0.85      0.75      0.80      2741\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  77  163]\n",
      " [ 515 1986]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# optimizer = AdamW(model.parameters())\n",
    "\n",
    "# class MyTrainer(Trainer):\n",
    "#     def create_optimizer(self):\n",
    "#         if not hasattr(self, \"optimizer\"):\n",
    "#             self.optimizer = AdamW(self.model.parameters(), lr=self.args.learning_rate)\n",
    "#         return self.optimizer\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     per_device_train_batch_size=8,\n",
    "#     num_train_epochs=1,\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=100,\n",
    "#     save_steps=1000,\n",
    "#     save_total_limit=3\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "# trainer.create_optimizer\n",
    "\n",
    "# for i in range(30):\n",
    "#     trainer.train()\n",
    "#     results = trainer.evaluate()\n",
    "#     print(results)\n",
    "#     prediction_outputs = trainer.predict(val_dataset)\n",
    "#     predicted_labels = np.argmax(prediction_outputs.predictions[0], axis=2)\n",
    "#     predicted_labels = predicted_labels.flatten()\n",
    "#     label_ids = prediction_outputs.label_ids.flatten()\n",
    "\n",
    "#     # y_pred = np.around(model.predict(val_dataset))\n",
    "\n",
    "#     print(metrics.classification_report(label_ids, predicted_labels))\n",
    "\n",
    "#     # f1 = f1_score(label_ids, predicted_labels, average=\"weighted\")\n",
    "    # print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    # acc = accuracy_score(label_ids, predicted_labels, normalize=True)\n",
    "    # print(f\"Accuracy: {acc}\")\n",
    "\n",
    "# print accuracy and loss at each step\n",
    "# what is the input and what is expected output for both classification and generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
